import os
import importlib
import logging
import pandas as pd
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt
from scipy.spatial.distance import cdist # ç”¨äºè®¡ç®—ç°‡é—´è·ç¦»

# å¼•å…¥æ ¸å¿ƒæ¨¡å—
import pipeline_llm 

# å¼ºåˆ¶é‡è½½ä»¥ç¡®ä¿ pipeline_llm.py çš„ä¿®æ”¹ç”Ÿæ•ˆ
importlib.reload(pipeline_llm)

from pipeline_llm import (
    SpaceConfig, 
    DataManager, 
    SpaceAnalyzer, 
    AgentInterface, 
    AdvancedEvaluator, 
    Visualizer, 
    HallucinationAnalyzer, 
    QualityEvaluator,
    AdvancedVisualizer
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ==========================================
# æ ¸å¿ƒåŠŸèƒ½å‡½æ•°å°è£…
# ==========================================

def build_global_network_data(adata, final_results, cfg):
    """
    [æ ¸å¿ƒä¿®å¤ç‰ˆ] æ„å»ºå…¨å±€äº¤äº’ç½‘ç»œæ•°æ® (CellChat é£æ ¼ - è´¨é‡ä½œç”¨å®šå¾‹ + è·ç¦»è¡°å‡)
    
    æ”¹è¿›ç‚¹ï¼š
    1. å¼•å…¥ Law of Mass Action: Score = Avg(L)_src * Avg(R)_tgt
    2. å¼•å…¥ Distance Decay: è·ç¦»è¶Šè¿‘ï¼Œæƒé‡è¶Šé«˜ï¼Œè€Œéç®€å•çš„ 0/1 æˆªæ–­ã€‚
    """
    logger.info("ğŸ”„ Calculating Weighted Source-Target interactions (Mass Action + Distance Decay)...")
    
    # 1. å‡†å¤‡æ•°æ®
    if 'target_cluster' not in adata.obs:
        return None

    adata.obs['target_cluster'] = adata.obs['target_cluster'].astype(str)
    unique_clusters = adata.obs['target_cluster'].unique()
    
    # 2. é¢„è®¡ç®—æ‰€æœ‰ Cluster çš„åŸºå› è¡¨è¾¾å‡å€¼ (Pre-compute Mean Expression)
    # è¿™æ­¥è‡³å…³é‡è¦ï¼Œç”¨äºåç»­è®¡ç®— L*R å¼ºåº¦
    logger.info("   - Pre-computing cluster gene expression profiles (Mean Expression)...")
    cluster_expr_means = {}
    
    # ä¸ºäº†åŠ é€Ÿï¼Œå…ˆè½¬æ¢æˆ DataFrame æˆ–è€…ç›´æ¥æ“ä½œ numpy
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾æ•°æ®å·²ç»å½’ä¸€åŒ– (log1p)ï¼Œå¦‚æœæ˜¯ count éœ€è¦å…ˆå½’ä¸€åŒ–
    for cid in unique_clusters:
        mask = adata.obs['target_cluster'] == cid
        if mask.sum() == 0: continue
        
        # è·å–è¯¥ Cluster çš„å¹³å‡è¡¨è¾¾é‡
        # å¤„ç†ç¨€ç–çŸ©é˜µ
        X_subset = adata.X[mask]
        if hasattr(X_subset, "toarray"):
            mean_expr = np.array(X_subset.mean(axis=0)).flatten()
        else:
            mean_expr = np.array(X_subset.mean(axis=0)).flatten()
            
        # å­˜å…¥å­—å…¸ï¼ŒKeyä¸ºåŸºå› åï¼ŒValueä¸ºè¡¨è¾¾å€¼
        cluster_expr_means[cid] = pd.Series(mean_expr, index=adata.var_names)

    # 3. å‡†å¤‡ç©ºé—´è®¡ç®—å‚æ•°
    if 'spatial_norm' in adata.obsm:
        coords_all = adata.obsm['spatial_norm']
        dist_thresh = getattr(cfg, 'adaptive_threshold', 0.05)
        logger.info(f"   - Using Normalized Coords (Threshold={dist_thresh:.4f})")
    else:
        coords_all = adata.obsm['spatial']
        dist_thresh = 250.0

    # 4. æ„å»ºè¾¹åˆ—è¡¨
    matrix_data = []
    
    for entry in final_results:
        src_cluster = str(entry['cluster_id'])
        txt = entry.get('llm_analysis', '')
        
        # éå† LLM è®¤ä¸ºæœ‰æ•ˆçš„äº’ä½œå¯¹
        for pair in entry.get('known_interactions', []):
            g1, g2 = pair.split(' -> ') # g1=Ligand, g2=Receptor
            
            # A. å¿…é¡»é€šè¿‡ LLM è¯­ä¹‰éªŒè¯
            if (g1 in txt and g2 in txt) and ("Segregated" not in txt):
                
                # è·å– Source çš„é…ä½“è¡¨è¾¾é‡
                if src_cluster not in cluster_expr_means: continue
                val_L = cluster_expr_means[src_cluster].get(g1, 0.0)
                
                # å¦‚æœ Source æ ¹æœ¬ä¸è¡¨è¾¾è¿™ä¸ªé…ä½“ (æˆ–è€…æä½)ï¼Œåˆ™è·³è¿‡
                if val_L < 0.01: continue 

                # è·å– Source åæ ‡
                mask_src = adata.obs['target_cluster'] == src_cluster
                coords_src = coords_all[mask_src]
                
                # éå†æ‰€æœ‰ Target Clusters
                for tgt_cluster in unique_clusters:
                    # B. è·å– Target çš„å—ä½“è¡¨è¾¾é‡
                    if tgt_cluster not in cluster_expr_means: continue
                    val_R = cluster_expr_means[tgt_cluster].get(g2, 0.0)
                    
                    # å¦‚æœ Target ä¸è¡¨è¾¾å—ä½“ï¼Œé€šè®¯å¼ºåº¦ä¸º 0
                    if val_R < 0.01: continue
                    
                    # === æ ¸å¿ƒæ”¹è¿› 1: è´¨é‡ä½œç”¨å®šå¾‹ (Mass Action) ===
                    # åŸºç¡€å¼ºåº¦ = Ligand_Expr * Receptor_Expr
                    # è¿™ç¡®ä¿äº†å—ä½“è¡¨è¾¾é‡é«˜çš„ Cluster è·å¾—æ›´é«˜çš„æƒé‡
                    base_strength = val_L * val_R
                    
                    min_dist = float('inf')
                    
                    # C. ç©ºé—´è·ç¦»è®¡ç®—
                    if src_cluster == tgt_cluster:
                        # è‡ªåˆ†æ³Œï¼šè·ç¦»è§†ä¸º 0ï¼Œæƒé‡æœ€é«˜
                        min_dist = 0.0
                        dist_factor = 1.0
                    else:
                        mask_tgt = adata.obs['target_cluster'] == tgt_cluster
                        coords_tgt = coords_all[mask_tgt]
                        
                        if len(coords_tgt) > 0:
                            # è®¡ç®—æœ€è¿‘è·ç¦»
                            dists = cdist(coords_src, coords_tgt)
                            min_dist = dists.min()
                            
                            # === æ ¸å¿ƒæ”¹è¿› 2: è·ç¦»è¡°å‡ (Soft Threshold) ===
                            if min_dist > dist_thresh:
                                dist_factor = 0.0 # è¶…è¿‡é˜ˆå€¼ï¼Œæˆªæ–­
                            else:
                                # çº¿æ€§è¡°å‡ï¼šè·ç¦»è¶Šè¿‘ (0)ï¼Œå› å­è¶Šæ¥è¿‘ 1ï¼›è·ç¦»æ¥è¿‘é˜ˆå€¼ï¼Œå› å­æ¥è¿‘ 0
                                dist_factor = 1.0 - (min_dist / dist_thresh)
                                # æˆ–è€…ä½¿ç”¨æŒ‡æ•°è¡°å‡ (æ›´å¹³æ»‘): 
                                # dist_factor = np.exp(-min_dist / (dist_thresh * 0.5))
                        else:
                            dist_factor = 0.0

                    # D. æœ€ç»ˆè¯„åˆ†
                    final_score = base_strength * dist_factor
                    
                    if final_score > 0:
                        matrix_data.append({
                            'source': src_cluster, 
                            'target': tgt_cluster, 
                            'count': 1,              # ä¿ç•™è®¡æ•°ä¾›å‚è€ƒ
                            'strength': final_score, # [æ–°å¢] çœŸå®çš„ç‰©ç†åŒ–å­¦å¼ºåº¦
                            'lr_pair': pair
                        })
    
    if not matrix_data:
        return None

    return pd.DataFrame(matrix_data)

# ==========================================
# ä¸»ç¨‹åºå…¥å£
# ==========================================

# ==========================================
# ä¸»ç¨‹åºå…¥å£ (Modified for GPT-4 Support)
# ==========================================

if __name__ == "__main__":
    # 1. åˆå§‹åŒ–é…ç½®
    data_name = 'squidpy_mouse_brain'
    print("ğŸš€ Initializing SpaceAgent Framework...")
    
    # ===ã€å…³é”®ä¿®æ”¹ç‚¹ã€‘åœ¨æ­¤å¤„é…ç½® LLM æ¨¡å¼å’Œå¯†é’¥ ===
    cfg = SpaceConfig(
        data_dir="./gold_data", 
        result_dir=f"./results_gold/{data_name}/",
        llm_source="api", 
        openai_api_key="sk-XXXXXXXXXXXXXXXXXXXXXXXX",  # <--- è¯·åœ¨æ­¤å¤„å¡«å…¥ä½ çš„çœŸå®å¯†é’¥
        openai_model="gpt-4", 
        gpu_id=0
    )

    # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
    dm = DataManager(cfg)
    sa = SpaceAnalyzer(cfg)
    agent = AgentInterface(cfg) # è¿™é‡Œä¼šè‡ªåŠ¨è¯»å– cfg.llm_source æ¥å†³å®šåŠ è½½å“ªä¸ªæ¨¡å‹

    # 2. æ•°æ®å‡†å¤‡
    print("\nğŸ“¦ Preparing Data...")
    dm.prepare_knowledge_base()
    h5ad_path = dm.load_dataset(source=data_name) 

    # 3. é¢„å¤„ç†ä¸æ‹“æ‰‘åˆ†æ
    print("\nğŸ”¬ Preprocessing & Analyzing Topology...")
    json_data, adata = dm.preprocess_adata(h5ad_path)
    
    if 'target_cluster' in adata.obs:
        print(f"âœ… Using Cluster Column: {adata.obs['target_cluster'].name}")
        print(f"   Clusters: {adata.obs['target_cluster'].unique().tolist()}")
    else:
        print("âš ï¸ Warning: No cluster column found.")

    # ç”Ÿæˆæ‹“æ‰‘æŠ¥å‘Š (æ³¨å…¥åŠŸèƒ½æ³¨é‡Š)
    json_data = sa.generate_reports(json_data, adata, data_manager=dm)
    
    # 4. LLM æ¨ç† (Agent ä¼šæ ¹æ® cfg è‡ªåŠ¨è°ƒç”¨ GPT-4)
    print(f"\nğŸ¤– Running LLM Inference (Mode: {cfg.llm_source})...")
    agent.load_model() # å¦‚æœæ˜¯ API æ¨¡å¼ï¼Œè¿™é‡Œä¼šåˆå§‹åŒ– OpenAI Client
    final_results = agent.run_inference(json_data)
    
    # å¤‡ä»½æ¨ç†ç»“æœ
    pd.DataFrame(final_results).to_json(
        os.path.join(cfg.result_dir, "raw_inference_results.json")
    )

    # ... (åç»­ä»£ç ä¿æŒä¸å˜: å¹»è§‰æµ‹è¯•ã€å¯è§†åŒ–ç­‰) ...
    # 5. å¹»è§‰æµ‹è¯• (Figure 4)
    print("\nğŸ“‰ Running Hallucination Evaluation (Figure 4)...")
    hallucination_checker = HallucinationAnalyzer(sa)
    dist_data = hallucination_checker.collect_distances(adata, final_results)

    Visualizer.plot_hallucination_test(
        dist_data, 
        save_path=os.path.join(cfg.result_dir, "Figure_4_Hallucination.pdf")
    )

    # 6. å®šé‡åŸºå‡†æµ‹è¯• (Figure 5 & Table)
    print("\nâš–ï¸ Running Quantitative Benchmark (Figure 5)...")
    ev = AdvancedEvaluator(adata, cfg)
    df_res = ev.run_benchmark(final_results)

    if df_res is not None:
        Visualizer.plot_benchmark_metrics(
            df_res, 
            save_path=os.path.join(cfg.result_dir, "Figure_5_Metrics.pdf")
        )
        df_res.to_csv(os.path.join(cfg.result_dir, "benchmark_metrics.csv"), index=False)
        
        print("\nğŸ” Fairness Check (Total Signal Retention):")
        for m in ["GeneAgent", "SpaceAgent"]:
            sub = df_res[df_res["Model"]==m]
            if not sub.empty:
                print(f"   - {m}: Avg Score={sub['Neighbor_Score'].mean():.4f}")

    # 7. å®šæ€§è¯„åˆ† (Table 3) - ä¹Ÿä¼šè‡ªåŠ¨ä½¿ç”¨ GPT-4 ä½œä¸ºè£åˆ¤
    print("\nğŸ‘©â€âš–ï¸ Running Qualitative Quality Evaluation (Table 3)...")
    judge = QualityEvaluator(cfg)
    quality_df = judge.evaluate_fairness(final_results)
    if not quality_df.empty:
        quality_df.to_csv(os.path.join(cfg.result_dir, "quality_scores.csv"), index=False)

    # 8. é«˜çº§å¯è§†åŒ–
    print("\nğŸ¨ Generating Publication-Ready Figures...")

    # 8.1 åŸºç¡€å›¾
    if len(final_results) > 0:
        av_base = Visualizer()
        Visualizer.plot_interaction_spatial(
            adata, final_results[0], 
            save_path=os.path.join(cfg.result_dir, "Figure_3A_Example.pdf")
        )
        Visualizer.plot_lr_colocalization_heatmap(
            adata, final_results[0],
            save_path=os.path.join(cfg.result_dir, "Figure_3B_Halo.pdf")
        )

    # 8.2 å…¨è²Œç½‘ç»œå›¾æ„å»º
    results_df = build_global_network_data(adata, final_results, cfg)

    if results_df is not None:
        av = AdvancedVisualizer(adata, cfg)
        
        matrix = av.plot_cluster_interaction_matrix(
            results_df, 
            value_col='strength',
            save_path=os.path.join(cfg.result_dir, "Figure_5_Interaction_Matrix.pdf")
        )

        if matrix is not None:
            print("ğŸŒƒ Generating Enhanced Dark-Mode Spatial Network...")
            av.plot_spatial_network_dark(
                matrix, 
                save_path=os.path.join(cfg.result_dir, "Figure_1_Spatial_Network_Dark.pdf"),
                background_type='celltype',
                transparency=0.5
            )
            
            print("ğŸŒ Generating Light-Mode Version for Comparison...")
            av.plot_spatial_network_light(
                matrix, 
                save_path=os.path.join(cfg.result_dir, "Figure_1_Spatial_Network_Light.pdf"),
                background_type='celltype'
            )
            
            # å¦‚æœéœ€è¦å¸¦ H&E èƒŒæ™¯å›¾çš„ç‰ˆæœ¬ (ä»… Visium æ•°æ®æœ‰æ•ˆ)
            av.plot_spatial_network_light(
                matrix, 
                save_path=os.path.join(cfg.result_dir, "Figure_1_Spatial_Network_Light_imgs.pdf"),
                background_type='image'
            )
            
            print("ğŸ» Generating PyCirclize Chord Diagram...")
            av.plot_chord_diagram(
                matrix, 
                save_path=os.path.join(cfg.result_dir, "Figure_6_Chord_Circlize.pdf")
            )

            print("ğŸŒŠ Generating Sankey Diagram...")
            av.plot_sankey_flow(
                matrix, 
                save_path=os.path.join(cfg.result_dir, "Figure_8_Sankey.pdf")
            )
            
    print("ğŸ«§ Generating DotPlot...")
    av = AdvancedVisualizer(adata, cfg)
    av.plot_lr_dotplot(
        final_results, 
        save_path=os.path.join(cfg.result_dir, "Figure_7_LR_DotPlot.pdf")
    )

    print("\nâœ… All experiments completed! Please check the './results_gold' folder.")